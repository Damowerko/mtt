{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import typing\n",
    "from typing import List\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "\n",
    "from mtt.models.convolutional import load_model\n",
    "from mtt.data import (\n",
    "    vector_to_image,\n",
    "    stack_images,\n",
    "    rolling_window,\n",
    "    VectorData,\n",
    "    StackedImageData,\n",
    ")\n",
    "from mtt.peaks import find_peaks\n",
    "from mtt.utils import compute_ospa_components, compute_ospa\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "sns.set_theme(\n",
    "    context=\"paper\",\n",
    "    style=\"whitegrid\",\n",
    "    rc={\n",
    "        \"figure.figsize\": (3.5, 3.5),\n",
    "        \"figure.dpi\": 150,\n",
    "        \"savefig.dpi\": 1000,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "        \"pdf.fonttype\": 42,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1\n",
    "simulation_idx = 40\n",
    "\n",
    "with open(f\"../data/test/{scale}km/simulations.pkl\", \"rb\") as f:\n",
    "    dataset_vectors: List[List[VectorData]] = pkl.load(f)\n",
    "\n",
    "images = map(\n",
    "    partial(vector_to_image, img_size=128 * scale), dataset_vectors[simulation_idx]\n",
    ")\n",
    "stacked = typing.cast(List[StackedImageData], rolling_window(stack_images(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all simulations where the sensor is within the simulation window\n",
    "for i, simulation_vectors in enumerate(dataset_vectors):\n",
    "    vectors = simulation_vectors[0]\n",
    "    sensors_within_window = np.all(\n",
    "        np.abs(vectors.sensor_positions)\n",
    "        <= np.array([vectors.simulator.window_width / 2] * 2),\n",
    "        axis=1,\n",
    "    )\n",
    "    if sensors_within_window.sum() > 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality = []\n",
    "for simulation in dataset_vectors:\n",
    "    cardinality.append([])\n",
    "    for step in simulation:\n",
    "        cardinality[-1].append(len(step.target_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = dataset_vectors[0][0].simulator\n",
    "window = simulator.window_width\n",
    "extent = [-window / 2, window / 2, -window / 2, window / 2]\n",
    "n_detections = (\n",
    "    simulator.n_sensors * np.pi * simulator.sensors[0].range_max ** 2 / 1000**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make CNN Predictions\n",
    "# model, name = load_model(\"../models/58c6fd8a.ckpt\")\n",
    "# model, name = load_model(\"wandb://damowerko/mtt/4uc51x21\")\n",
    "# model, name = load_model(\"wandb://damowerko/mtt/rmwq3ref\")\n",
    "# model, name = load_model(\"wandb://damowerko/mtt/eiytli6p\")\n",
    "# model, name = load_model(\"wandb://damowerko/mtt/e7ivqipk\")\n",
    "model, name = load_model(\"../models/e7ivqipk.ckpt\")\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_idx = -1\n",
    "method = \"gmm\"\n",
    "n_peaks_scale = 1.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = torch.stack([d.sensor_images for d in stacked], dim=0)\n",
    "    output_images = model(x.cuda())\n",
    "    pred_img = output_images.clamp(min=0).cpu().numpy() * n_peaks_scale\n",
    "\n",
    "n = pred_img.shape[0]\n",
    "width = simulator.simulation_width\n",
    "window = simulator.window_width\n",
    "extent = [-window / 2, window / 2, -window / 2, window / 2]\n",
    "\n",
    "predictions_cnn = []\n",
    "for i in trange(n):\n",
    "    predictions_cnn.append(\n",
    "        find_peaks(pred_img[i][filt_idx], width=window, method=method).means\n",
    "    )\n",
    "\n",
    "cardinality_cnn = pred_img.sum(axis=(-1, -2)).mean().item()\n",
    "print(f\"Mean cardinality estimate: {cardinality_cnn:.2f}\")\n",
    "cardinality_truth = np.mean(\n",
    "    [len(d.info[filt_idx][\"target_positions\"]) for d in stacked]\n",
    ")\n",
    "print(f\"Mean cardinality truth: {cardinality_truth}\")\n",
    "print(f\"Ratio {cardinality_truth / cardinality_cnn:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_idx = 99\n",
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, axs = plt.subplots(1, 3, sharey=True, figsize=(7.0, 3.5))\n",
    "    imshow_kwargs = dict(\n",
    "        extent=extent,\n",
    "        origin=\"lower\",\n",
    "        cmap=\"gray_r\",\n",
    "    )\n",
    "\n",
    "    axs[0].set_title(\"Sensor Measurements\")\n",
    "    axs[0].imshow(stacked[step_idx].sensor_images[filt_idx].cpu(), **imshow_kwargs)\n",
    "    axs[0].plot(\n",
    "        *stacked[step_idx].info[filt_idx][\"sensor_positions\"].T, \"ro\", markersize=5\n",
    "    )\n",
    "    axs[0].set_xlim(xmin=extent[0], xmax=extent[1])\n",
    "    axs[0].set_ylim(ymin=extent[2], ymax=extent[3])\n",
    "\n",
    "    axs[1].set_title(\"Target Positions\")\n",
    "    axs[1].imshow(stacked[step_idx].target_images[filt_idx].cpu(), **imshow_kwargs)\n",
    "\n",
    "    axs[2].set_title(\"CNN Output\")\n",
    "    axs[2].imshow(pred_img[step_idx][filt_idx], **imshow_kwargs)\n",
    "\n",
    "    axs[0].set_ylabel(\"$y$ (m)\")\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"$x$ (m)\")\n",
    "\n",
    "    plt.savefig(\"../figures/mtt_images.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    figscale = 2.0\n",
    "    fontsize = 22\n",
    "    markersize = figscale * 5\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(figscale * 7.5, figscale * 3))\n",
    "    for ax in axs:\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(extent[:2])\n",
    "        ax.set_ylim(extent[2:])\n",
    "\n",
    "    imshow_kwargs = dict(\n",
    "        extent=extent,\n",
    "        origin=\"lower\",\n",
    "        cmap=\"gray_r\",\n",
    "    )\n",
    "\n",
    "    # Plot measurement positions\n",
    "    measurements = np.concatenate(\n",
    "        stacked[step_idx].info[filt_idx][\"measurements\"]\n",
    "        + stacked[step_idx].info[filt_idx][\"clutter\"],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    axs[0].set_title(\"Sensor Measurements\", fontsize=fontsize)\n",
    "    axs[0].plot(*measurements.T, \"b.\", markersize=markersize)\n",
    "\n",
    "    axs[1].set_title(\"Measurement Image\", fontsize=fontsize)\n",
    "    axs[1].imshow(stacked[step_idx].sensor_images[filt_idx].cpu(), **imshow_kwargs)\n",
    "    axs[1].set_xlim(xmin=extent[0], xmax=extent[1])\n",
    "    axs[1].set_ylim(ymin=extent[2], ymax=extent[3])\n",
    "\n",
    "    axs[2].set_title(\"CNN Output\", fontsize=fontsize)\n",
    "    axs[2].imshow(pred_img[step_idx][filt_idx], **imshow_kwargs)\n",
    "\n",
    "    axs[3].set_title(\"Position Estimates\", fontsize=fontsize)\n",
    "    axs[3].plot(*predictions_cnn[step_idx].T, \"ro\", markersize=markersize)\n",
    "\n",
    "    plt.savefig(\"../figures/poster/mtt_pipeline.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_energy = np.mean(\n",
    "    [pos_img[1].cpu().clamp(min=0).sum(dim=[-1, -2]) for _, pos_img, _ in stacked]\n",
    ")\n",
    "mean_cardinality = np.mean(\n",
    "    [len(info[\"target_positions\"]) for _, _, infos in stacked for info in infos]\n",
    ")\n",
    "mean_energy, mean_cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_true = np.array([len(d[2][filt_idx][\"target_positions\"]) for d in stacked])\n",
    "card_cnn = np.array([len(p) for p in predictions_cnn])\n",
    "card_img = pred_img.sum(axis=(-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cardinality\n",
    "plt.step(np.arange(n), card_true, label=\"Ground Truth\")\n",
    "plt.step(np.arange(n), card_cnn, label=\"Extracted\", linestyle=\"dashed\")\n",
    "plt.step(np.arange(n), card_img, label=\"CNN Output Sum\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"# of targets\")\n",
    "# legend to the right of axis\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.05), loc=\"lower center\", ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ospa_cnn = []\n",
    "ospa_cnn_components = []\n",
    "for idx in range(n):\n",
    "    sensor_img, target_img, info = stacked[idx]\n",
    "    target_positions = info[-1][\"target_positions\"]\n",
    "    ospa_cnn += [compute_ospa(target_positions, predictions_cnn[idx], 500, p=2)]\n",
    "    ospa_cnn_components += [\n",
    "        compute_ospa_components(target_positions, predictions_cnn[idx], 500, p=2)\n",
    "    ]\n",
    "\n",
    "ospa_cnn_components = np.array(ospa_cnn_components)\n",
    "print(f\"Mean OSPA: {np.mean(ospa_cnn):.2f}m \\u00B1 {np.std(ospa_cnn):.2f}m\")\n",
    "print(\n",
    "    f\"Mean OSPA (Position): {np.mean(ospa_cnn_components[:,0]):.2f}m \\u00B1 {np.std(ospa_cnn_components[:,0]):.2f}m\"\n",
    ")\n",
    "print(\n",
    "    f\"Mean OSPA (Cardinality): {np.mean(ospa_cnn_components[:,1]):.2f}m \\u00B1 {np.std(ospa_cnn_components[:,1]):.2f}m\"\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.step(np.arange(n), ospa_cnn, label=\"CNN\")\n",
    "# plt.step(np.arange(n), ospa_cnn_components[:,0], label=\"CNN (Position)\")\n",
    "# plt.step(np.arange(n), ospa_cnn_components[:,1], label=\"CNN (Cardinality)\")\n",
    "plt.ylabel(\"OSPA (m)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a figure of the CNN results at different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "scales = list(range(1, 6))\n",
    "\n",
    "for scale in scales:\n",
    "    with open(f\"../data/test/{scale}km/simulations.pkl\", \"rb\") as f:\n",
    "        dataset_vectors: List[List[VectorData]] = pkl.load(f)\n",
    "    stacked = simulation_window(\n",
    "        stack_images(\n",
    "            map(\n",
    "                partial(vector_to_image, img_size=128 * scale, device=\"cuda\"),\n",
    "                dataset_vectors[rng.integers(100)][:20],\n",
    "            )\n",
    "        ),\n",
    "        idx=\"random\",\n",
    "    )[0]\n",
    "    sensor_img = stacked.sensor_images[filt_idx].cpu().numpy()\n",
    "    target_img = stacked.target_images[filt_idx].cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        cnn_img = model(stacked.sensor_images.cuda()).squeeze().cpu().numpy()\n",
    "\n",
    "    images += [(sensor_img, target_img, cnn_img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, axs = plt.subplots(2, len(images), figsize=(7.5, 3.0))\n",
    "for scale, (sensor_img, target_img, cnn_img) in zip(scales, images):\n",
    "    ax_sensor, ax_cnn = axs[:, scale - 1]\n",
    "\n",
    "    cmap = \"gray_r\"\n",
    "\n",
    "    ax_sensor.imshow(np.log(sensor_img + 1e-3), cmap=cmap)\n",
    "    ax_sensor.set_title(f\"{scale}km wide area\")\n",
    "    ax_cnn.imshow(cnn_img, cmap=cmap)\n",
    "\n",
    "    for ax in (ax_sensor, ax_cnn):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    if scale == scales[0]:\n",
    "        ax_sensor.set_ylabel(\"Sensor Image\")\n",
    "        ax_cnn.set_ylabel(\"CNN Output\")\n",
    "plt.savefig(\"../figures/mtt_transfer.pdf\")\n",
    "plt.savefig(\"../figures/mtt_transfer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"), sns.plotting_context(\"poster\"):\n",
    "    fig, axs = plt.subplots(2, len(images), figsize=(15.0, 6.0))\n",
    "    for scale, (sensor_img, target_img, cnn_img) in zip(scales, images):\n",
    "        ax_sensor, ax_cnn = axs[:, scale - 1]\n",
    "\n",
    "        cmap = \"gray_r\"\n",
    "\n",
    "        ax_sensor.imshow(np.log(sensor_img + 1e-3), cmap=cmap)\n",
    "        ax_sensor.set_title(f\"{scale}km wide area\")\n",
    "        ax_cnn.imshow(cnn_img, cmap=cmap)\n",
    "\n",
    "        for ax in (ax_sensor, ax_cnn):\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        if scale == scales[0]:\n",
    "            ax_sensor.set_ylabel(\"Sensor Image\")\n",
    "            ax_cnn.set_ylabel(\"CNN Output\")\n",
    "plt.savefig(\"../figures/poster/mtt_transfer.pdf\")\n",
    "plt.savefig(\"../figures/poster/mtt_transfer.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
