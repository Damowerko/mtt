{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from typing import List, Dict\n",
    "\n",
    "import imageio\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from mtt.models.convolutional import load_model\n",
    "from mtt.data.image import (\n",
    "    StackedImageData,\n",
    "    to_image,\n",
    "    rolling_window,\n",
    "    stack_images,\n",
    ")\n",
    "from mtt.data.sim import SimulationStep\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading simulation 2 for scales [1, 2] km.\n"
     ]
    }
   ],
   "source": [
    "scales = [1, 2]\n",
    "simulation_idx = 2\n",
    "print(f\"Loading simulation {simulation_idx} for scales {scales} km.\")\n",
    "\n",
    "# load data for each scale\n",
    "data: Dict[int, List[StackedImageData]] = {}\n",
    "for scale in scales:\n",
    "    with open(f\"data/test/{scale}km/simulations.pkl\", \"rb\") as f:\n",
    "        simulation: List[SimulationStep] = pickle.load(f)[simulation_idx]\n",
    "    images = stack_images([to_image(data, img_size=128 * scale) for data in simulation])\n",
    "    data[scale] = rolling_window(images)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.9.4 to v2.2.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint models/e7ivqipk.ckpt`\n"
     ]
    }
   ],
   "source": [
    "# Make CNN Predictions\n",
    "from mtt.peaks import find_peaks\n",
    "\n",
    "model, name = load_model(\"models/e7ivqipk.ckpt\")\n",
    "model = model.cuda()\n",
    "\n",
    "output_images = {}\n",
    "output_estimates = {}\n",
    "with torch.no_grad():\n",
    "    for scale in scales:\n",
    "        output_images[scale] = []\n",
    "        output_estimates[scale] = []\n",
    "        for d in data[scale]:\n",
    "            output_image = (\n",
    "                model.forward(d.sensor_images.cuda())[-1].detach().cpu().numpy()\n",
    "            )\n",
    "            output_images[scale].append(output_image)\n",
    "\n",
    "            output_estimate = find_peaks(output_image, d.info[-1][\"window\"]).means\n",
    "            output_estimates[scale].append(output_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1000, 500) to (1008, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1000, 500) to (1008, 512) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "from mtt.visualize import plot_mtt\n",
    "\n",
    "idx = 0\n",
    "out_dir = f\"data/out/video/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for scale in scales:\n",
    "    # generate stills\n",
    "    stills = []\n",
    "    for idx in range(len(data[scale])):\n",
    "        fig = plot_mtt(\n",
    "            data[scale][idx].sensor_images[-1].cpu().numpy(),\n",
    "            output_images[scale][idx],\n",
    "            data[scale][idx].info[-1],\n",
    "            estimates=output_estimates[scale][idx],\n",
    "            plot_clutter=False,\n",
    "            plot_measurements=False,\n",
    "        )\n",
    "        # save fig to numpy array\n",
    "        fig.canvas.draw()\n",
    "        image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)  # type: ignore\n",
    "        image = image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "        stills.append(image)\n",
    "        plt.close()\n",
    "    # make video using imageio ffmpeg\n",
    "    imageio.mimsave(f\"{out_dir}/{scale}km.mp4\", stills, fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
