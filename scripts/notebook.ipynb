{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtt.simulator import Simulator\n",
    "from mtt.data import OnlineDataset\n",
    "\n",
    "init_simulator = lambda: Simulator(\n",
    "    width=1000,\n",
    "    p_initial=4,\n",
    "    p_birth=2,\n",
    "    p_survival=0.95,\n",
    "    p_clutter=1e-4,\n",
    "    p_detection=0.95,\n",
    "    sigma_motion=5.0,\n",
    "    sigma_initial_state=(50.0, 50.0, 2.0),\n",
    "    n_sensors=1,\n",
    "    noise_range=10.0,\n",
    "    noise_bearing=0.1,\n",
    "    dt=0.1,\n",
    ")\n",
    "dataset = OnlineDataset(n_steps=100, sigma_position=0.01, length=20, img_size=128, init_simulator=init_simulator)\n",
    "dataset = list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of targets: mean = 19.45, std = 4.02\n",
      "position std: [717.36619456 434.89755688]\n"
     ]
    }
   ],
   "source": [
    "positions = [info[-1][\"target_positions\"] for *_, info in dataset]\n",
    "n_targets = [len(pos) for pos in positions]\n",
    "print(f\"# of targets: mean = {np.mean(n_targets):0.2f}, std = {np.std(n_targets):0.2f}\")\n",
    "print(f\"position std: {np.std(np.concatenate(positions), axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Conv2dCoder                              --                        --\n",
       "├─Sequential: 1-1                        [1, 128, 16, 16]          --\n",
       "│    └─Conv2d: 2-1                       [1, 128, 64, 64]          207,488\n",
       "│    └─ReLU: 2-2                         [1, 128, 64, 64]          --\n",
       "│    └─Conv2d: 2-3                       [1, 128, 32, 32]          1,327,232\n",
       "│    └─ReLU: 2-4                         [1, 128, 32, 32]          --\n",
       "│    └─Conv2d: 2-5                       [1, 128, 16, 16]          1,327,232\n",
       "│    └─ReLU: 2-6                         [1, 128, 16, 16]          --\n",
       "├─Sequential: 1-2                        [1, 128, 16, 16]          --\n",
       "│    └─Conv2d: 2-7                       [1, 1024, 16, 16]         132,096\n",
       "│    └─ReLU: 2-8                         [1, 1024, 16, 16]         --\n",
       "│    └─Conv2d: 2-9                       [1, 1024, 16, 16]         1,049,600\n",
       "│    └─ReLU: 2-10                        [1, 1024, 16, 16]         --\n",
       "│    └─Conv2d: 2-11                      [1, 128, 16, 16]          131,200\n",
       "│    └─ReLU: 2-12                        [1, 128, 16, 16]          --\n",
       "├─Sequential: 1-3                        [1, 20, 128, 128]         --\n",
       "│    └─ConvTranspose2d: 2-13             [1, 128, 32, 32]          1,327,232\n",
       "│    └─ReLU: 2-14                        [1, 128, 32, 32]          --\n",
       "│    └─ConvTranspose2d: 2-15             [1, 128, 64, 64]          1,327,232\n",
       "│    └─ReLU: 2-16                        [1, 128, 64, 64]          --\n",
       "│    └─ConvTranspose2d: 2-17             [1, 20, 128, 128]         207,380\n",
       "│    └─Identity: 2-18                    [1, 20, 128, 128]         --\n",
       "==========================================================================================\n",
       "Total params: 7,036,692\n",
       "Trainable params: 7,036,692\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 13.08\n",
       "==========================================================================================\n",
       "Input size (MB): 1.31\n",
       "Forward/backward pass size (MB): 17.83\n",
       "Params size (MB): 28.15\n",
       "Estimated Total Size (MB): 47.28\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import guild.ipy as guild\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from mtt.models import Conv2dCoder\n",
    "from torchinfo import summary\n",
    "\n",
    "runs = guild.runs()\n",
    "runs = runs[runs.started > \"2022-04-04\"]\n",
    "matching = runs.run.apply(lambda run: run.value.short_id == \"6c0cf3b6\")\n",
    "dir = runs[matching].iloc[0].run.value.dir\n",
    "checkpoint_file = glob(os.path.join(dir, \"**/epoch*.ckpt\"))[0]\n",
    "model = Conv2dCoder.load_from_checkpoint(checkpoint_file)\n",
    "summary(model, (1,) + model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "\n",
    "n_past = 5\n",
    "width = 1000\n",
    "extent = (-width / 2, width / 2, -width / 2, width / 2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "def animate(i):\n",
    "    sensor_img, position_img, info = dataset[i]\n",
    "    with torch.no_grad():\n",
    "        output_img = model(sensor_img[None,...].cuda())[0, -n_past].cpu()\n",
    "    sensor_img = sensor_img[-n_past].numpy()\n",
    "    position_img = position_img[-n_past].numpy()\n",
    "    info = info[-n_past]\n",
    "\n",
    "    target_positions = info[\"target_positions\"]\n",
    "    measurements = np.concatenate(info[\"measurements\"])\n",
    "    clutter = np.concatenate(info[\"clutter\"])\n",
    "\n",
    "    for i in range(len(ax)):\n",
    "        ax[i].clear()\n",
    "        ax[i].plot(*target_positions.T, \"r.\", markersize=5)\n",
    "        ax[i].plot(*measurements.T, \"bx\", markersize=5)\n",
    "        ax[i].plot(*clutter.T, \"g^\", markersize=5)\n",
    "    \n",
    "    ax[0].set_title(f\"Sensor Measurements\")\n",
    "    ax[1].set_title(f\"Target Positions (Ground Truth)\")\n",
    "    ax[2].set_title(f\"CNN Output\")\n",
    "\n",
    "    ax[0].imshow(sensor_img, extent=extent, origin=\"lower\", cmap=\"gray_r\")\n",
    "    ax[1].imshow(position_img, extent=extent, origin=\"lower\", cmap=\"gray_r\")\n",
    "    ax[2].imshow(output_img, extent=extent, origin=\"lower\", cmap=\"gray_r\")\n",
    "    ax[1].legend([\"Target Position\", \"Sensor Measurement\", \"Clutter\"], loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3, fancybox=True)\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=len(dataset), interval=100)\n",
    "# HTML(anim.to_jshtml())\n",
    "anim.save(\"./animation.mp4\", fps=10, dpi=150, bitrate=-1)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d254b5343a29bfdb0403307d8b5f18b81144efcf3f8f8805fab4544319af905"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('mtt': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
